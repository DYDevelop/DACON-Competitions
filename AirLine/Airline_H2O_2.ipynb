{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Done.\n",
      "test Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정\n",
    "\n",
    "def csv_to_parquet(csv_path, save_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(f'./{save_name}.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    print(save_name, 'Done.')\n",
    "# csv_to_parquet('./train.csv', 'train')\n",
    "# csv_to_parquet('./test.csv', 'test')\n",
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "train['Day_of_Month'] = train.apply(lambda x: np.sin(((sum(mom[:(int(x['Month'])-1)]) + int(x['Day_of_Month'])) / 365) * np.pi), axis=1)\n",
    "test['Day_of_Month'] = test.apply(lambda x: np.sin(((sum(mom[:(int(x['Month'])-1)]) + int(x['Day_of_Month'])) / 365) * np.pi), axis=1)\n",
    "train['Estimated_Departure_Time'] = train.apply(lambda x: np.sin((((int(x['Estimated_Departure_Time']) // 100) * 60 + (int(x['Estimated_Departure_Time']) % 100)) / 1439) * np.pi) if pd.notnull(x['Estimated_Departure_Time']) else None, axis=1)\n",
    "test['Estimated_Departure_Time'] = test.apply(lambda x: np.sin((((int(x['Estimated_Departure_Time']) // 100) * 60 + (int(x['Estimated_Departure_Time']) % 100)) / 1439) * np.pi) if pd.notnull(x['Estimated_Departure_Time']) else None, axis=1)\n",
    "train['Estimated_Arrival_Time'] = train.apply(lambda x: np.sin((((int(x['Estimated_Arrival_Time']) // 100) * 60 + (int(x['Estimated_Arrival_Time']) % 100)) / 1439) * np.pi) if pd.notnull(x['Estimated_Arrival_Time']) else None, axis=1)\n",
    "test['Estimated_Arrival_Time'] = test.apply(lambda x: np.sin((((int(x['Estimated_Arrival_Time']) // 100) * 60 + (int(x['Estimated_Arrival_Time']) % 100)) / 1439) * np.pi) if pd.notnull(x['Estimated_Arrival_Time']) else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['ID', 'Month', 'Origin_Airport', 'Destination_Airport', 'Cancelled', 'Diverted'])\n",
    "test = test.drop(columns=['ID', 'Month', 'Origin_Airport', 'Destination_Airport', 'Cancelled', 'Diverted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #레이블(Delay)을 제외한 결측값이 존재하는 변수들을 학습 데이터의 최빈값으로 대체합니다\n",
    "# #가장 많이 나온 값들로 NaN을 대체함\n",
    "# NaN_col = ['Origin_State','Destination_State','Airline','Estimated_Departure_Time', 'Estimated_Arrival_Time','Carrier_Code(IATA)','Carrier_ID(DOT)']\n",
    "\n",
    "# for col in NaN_col:\n",
    "#     mode = train[col].mode()[0]\n",
    "#     train[col] = train[col].fillna(mode)\n",
    "    \n",
    "#     if col in test.columns:\n",
    "#         test[col] = test[col].fillna(mode)\n",
    "# print('Done.')\n",
    "\n",
    "threshold = 10\n",
    "category_column = ['Origin_Airport_ID', 'Origin_State', 'Destination_Airport_ID', 'Destination_State', 'Airline','Carrier_Code(IATA)', 'Carrier_ID(DOT)', 'Tail_Number']\n",
    "for column_name in category_column:\n",
    "    # value_counts() 메서드를 사용하여 해당 column에서 각 값의 빈도수 계산\n",
    "    value_counts = train[column_name].value_counts()\n",
    "\n",
    "    # 빈도수가 threshold보다 작은 값들의 인덱스를 추출하여 리스트로 저장\n",
    "    to_remove = value_counts[value_counts < threshold].index.tolist()\n",
    "\n",
    "    # to_remove 리스트에 속하지 않은 row들로 이루어진 새로운 dataframe 생성\n",
    "    train = train[~train[column_name].isin(to_remove)]\n",
    "    \n",
    "def to_number(x):\n",
    "    if x == None: return -1\n",
    "    elif x == 'Delayed': return 1\n",
    "    else: return 0\n",
    "    \n",
    "train.loc[:, 'Delay'] = train['Delay'].apply(lambda x: to_number(x)) # 0 : Not Delayed  //  1 : Delayed\n",
    "\n",
    "# Quantify qualitative variables\n",
    "# 정성적 변수는 LabelEncoder를 사용하여 숫자로 인코딩됩니다.\n",
    "qual_col = ['Origin_State', 'Destination_State', 'Airline', 'Carrier_Code(IATA)', 'Tail_Number']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train[i])\n",
    "    train[i] = le.transform(train[i])\n",
    "    \n",
    "    for label in set(test[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test[i] = le.transform(test[i])\n",
    "\n",
    "train = train.dropna()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Delay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_row_0 = train.loc[train['Delay'] == 0]\n",
    "selected_row_1 = train.loc[train['Delay'] == 1]\n",
    "if len(selected_row_0) > len(selected_row_1): selected_row_0 = selected_row_0.sample(n=len(selected_row_1)//3)\n",
    "# else: selected_row_1 = selected_row_1.sample(n=len(selected_row_0), replace=True)\n",
    "train_0to1 = pd.concat([selected_row_0, selected_row_1], ignore_index=True)\n",
    "train_0to1 = train_0to1.sample(frac=1)\n",
    "# selected_row_null = train.loc[train['Delay'] == -1]\n",
    "# selected_row_null = selected_row_null.sample(n = 31813)\n",
    "# train_sorted = pd.concat([selected_row_0, selected_row_1, selected_row_null], ignore_index=True)\n",
    "# train_sorted = train_sorted.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0to1['Delay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. h2o 분석 준비하기 ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "h2o.init()\n",
    "h2o.no_progress()\n",
    "################################################################\n",
    "## make dataset\n",
    "# Identify the response and set of predictors\n",
    "y = \"Delay\"\n",
    "x = list(train_0to1.columns)  #if x is defined as all columns except the response, then x is not required\n",
    "x.remove(y)\n",
    "\n",
    "# # data_df을 8:2로 나눈다, 50 : 13\n",
    "# train, valid = train_test_split(train,\n",
    "#                                 test_size=0.2, \n",
    "#                                 shuffle=True)\n",
    "h2o_train = h2o.H2OFrame(train_0to1)\n",
    "# h2o_valid = h2o.H2OFrame(valid)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "h2o_train[y] = h2o_train[y].asfactor()\n",
    "# h2o_valid[y] = h2o_valid[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_1 = H2OAutoML(max_models = 25,\n",
    "                balance_classes=True,\n",
    "\t\t        seed = 1)\n",
    "aml_1.train(x = x, y = y, training_frame=h2o_train)\n",
    "lb_1 = aml_1.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_row_null = train.loc[train['Delay'] == -1]\n",
    "selected_row_null = selected_row_null.drop(columns=['Delay'])\n",
    "h2o_null = h2o.H2OFrame(selected_row_null)\n",
    "m_1 = aml_1.get_best_model()\n",
    "preds = m_1.predict(h2o_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_row_null['Delay'] = preds['predict'].values\n",
    "selected_row_0 = train.loc[train['Delay'] == 0]\n",
    "selected_row_1 = train.loc[train['Delay'] == 1]\n",
    "train_filled = pd.concat([selected_row_0, selected_row_1, selected_row_null], ignore_index=True)\n",
    "train_filled = train_filled.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filled['Delay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_row_0 = train_filled.loc[train_filled['Delay'] == 0]\n",
    "# selected_row_1 = train_filled.loc[train_filled['Delay'] == 1]\n",
    "# # if len(selected_row_0) < len(selected_row_1): selected_row_1 = selected_row_1.sample(n=len(selected_row_0)//2)\n",
    "# # else: selected_row_0 = selected_row_0.sample(n=len(selected_row_1)//2)\n",
    "# train_filled = pd.concat([selected_row_0, selected_row_1], ignore_index=True)\n",
    "# train_filled = train_filled.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_filled['Delay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "## make dataset\n",
    "# Identify the response and set of predictors\n",
    "y = \"Delay\"\n",
    "x = list(train_filled.columns)  #if x is defined as all columns except the response, then x is not required\n",
    "x.remove(y)\n",
    "\n",
    "# # data_df을 8:2로 나눈다, 50 : 13\n",
    "# train, valid = train_test_split(train,\n",
    "#                                 test_size=0.2, \n",
    "#                                 shuffle=True)\n",
    "h2o_train = h2o.H2OFrame(train_filled)\n",
    "# h2o_valid = h2o.H2OFrame(valid)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "h2o_train[y] = h2o_train[y].asfactor()\n",
    "# h2o_valid[y] = h2o_valid[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_models = 25,\n",
    "                balance_classes=True,\n",
    "\t\t        seed = 1)\n",
    "aml.train(x = x, y = y, training_frame=h2o_train)\n",
    "lb = aml.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_test = h2o.H2OFrame(test)\n",
    "m = aml.get_best_model(criterion=\"logloss\")\n",
    "h2o.save_model(model=m)\n",
    "preds = m.predict(h2o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = preds.as_data_frame().drop(columns=['predict']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=y_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('submission.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
